{
 "cells": [
  {
   "cell_type": "code",
   "id": "b366ef33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T08:26:01.031782Z",
     "start_time": "2024-06-08T08:25:59.182528Z"
    }
   },
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "import scipy.spatial as sp, scipy.cluster.hierarchy as hc\n",
    "\n",
    "from Utils.customPipelines import *\n",
    "from Utils.preprocessing import *\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "\n",
    "sns.set(font=\"monospace\")\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_STATE = 632"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'collinearity'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m stats\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspatial\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msp\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcluster\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhierarchy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mhc\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mUtils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcustomPipelines\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mUtils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m jaccard_score\n",
      "File \u001B[0;32m~/PycharmProjects/QF632_Project/Utils/customPipelines.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpipeline\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Pipeline\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mUtils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpipelineComponents\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[1;32m      5\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/QF632_Project/Utils/pipelineComponents.py:12\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpipeline\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (FeatureUnion, _fit_transform_one, _transform_one)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StandardScaler, LabelBinarizer, OrdinalEncoder\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcollinearity\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SelectNonCollinear\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m## Custom Estimators\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# https://sklearn-template.readthedocs.io/en/latest/user_guide.html\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# https://towardsdatascience.com/custom-transformers-and-ml-data-pipelines-with-python-20ea2a7adb65\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m#   raw data  -->  clean data   -->  categorical feature selector  ->  imputer  ->  categorical encoder ->  Union feature  ->  3 x ML models  ->  Ensemble\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m#                                \\-->  numerical feature selector  ->  outlier handler  ->  imputer  --/\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mFeatureSelector\u001B[39;00m(BaseEstimator, TransformerMixin):\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'collinearity'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "e2fd00cf",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "fc2f86da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T08:26:01.036156Z",
     "start_time": "2024-06-08T08:26:01.036056Z"
    }
   },
   "source": [
    "# Load the dataset\n",
    "file_path = 'Data/Analyst_Coverage.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.shape)\n",
    "df.sample(15)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b4f004891988d83f",
   "metadata": {},
   "source": [
    "Course project 3\n",
    "\n",
    "○ Building an unsupervised model to cluster stocks, modeling covariance/distance matrix structures\n",
    "\n",
    "○ Understanding how companies/stocks are grouped together and investigate better ways of recategorizing peer groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcfb8faa380f239",
   "metadata": {},
   "source": [
    "GICS industry code (8 digits) consists of:\n",
    "\n",
    "11 sectors, 24 industry groups, 69 industries and 158 sub-industries\n",
    "\n",
    "(sector | industry group | industry | sub-industry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe87e204",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "- Check for NA values\n",
    "- Check for duplicates\n",
    "- Standardise row types\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5da577a4",
   "metadata": {},
   "source": [
    "# Drop rows with missing data (Assuming missing RATING means not properly covered by analyst)\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)\n",
    "print()\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(\"Number of duplicate rows:\", duplicates)\n",
    "print()\n",
    "# Check Types\n",
    "print(df.info())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4c4d0a65",
   "metadata": {},
   "source": [
    "We will impute the NaN values for ratings with the mean ratings per industry"
   ]
  },
  {
   "cell_type": "code",
   "id": "5de07fea",
   "metadata": {},
   "source": [
    "df_mean_rating = df[[\"GICS_SECTOR_NAME\", \"RATING\"]].dropna().groupby([\"GICS_SECTOR_NAME\"], as_index=False).mean()\n",
    "df_imputed = df[df[\"RATING\"].isna()].copy()\n",
    "df_imputed = df_imputed.drop(columns=[\"RATING\"]).merge(df_mean_rating, on=[\"GICS_SECTOR_NAME\"])\n",
    "df_clean = pd.concat([df.dropna(), df_imputed])\n",
    "\n",
    "print(df_clean.shape)\n",
    "df_clean.sample(7)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6278b88c",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "25fdccf5",
   "metadata": {},
   "source": [
    "# Analyze Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6dd8b4",
   "metadata": {},
   "source": [
    "## 1. Which company has the higher analyst coverage?"
   ]
  },
  {
   "cell_type": "code",
   "id": "d74f41a2",
   "metadata": {},
   "source": [
    "# Calculate the analyst coverage for each company\n",
    "df_coverage = df_clean[['BBTICKER', 'ANALYST']].copy()\n",
    "df_coverage = df_coverage.drop_duplicates()\n",
    "company_coverage = df_coverage['BBTICKER'].value_counts()\n",
    "\n",
    "# Plot the top 10 companies with the highest analyst coverage\n",
    "top_10_company_coverage = company_coverage.head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_10_company_coverage.plot(kind='bar')\n",
    "plt.title('Top 10 Companies with Highest Analyst Coverage')\n",
    "plt.xlabel('Company')\n",
    "plt.ylabel('Number of Analysts')\n",
    "plt.show()\n",
    "\n",
    "# Find the company with the highest analyst coverage\n",
    "most_covered_company = company_coverage.idxmax()\n",
    "most_covered_company_coverage = company_coverage.max()\n",
    "\n",
    "print(f\"The company with the highest analyst coverage is '{most_covered_company}' with {most_covered_company_coverage} analysts covering it.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "749b33f8",
   "metadata": {},
   "source": [
    "## 2. Which analyst covers the most companies?"
   ]
  },
  {
   "cell_type": "code",
   "id": "3a65d578",
   "metadata": {},
   "source": [
    "# Calculate the number of companies each analyst covers\n",
    "# analyst_coverage = df.groupby('ANALYST')['BBTICKER'].nunique()\n",
    "analyst_coverage = df_coverage['ANALYST'].value_counts()\n",
    "\n",
    "# Plot the top 10 analysts covering the most companies\n",
    "# top_10_analyst_coverage = analyst_coverage.sort_values(ascending=False).head(10)\n",
    "top_10_analyst_coverage = analyst_coverage.head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_10_analyst_coverage.plot(kind='bar')\n",
    "\n",
    "plt.title('Top 10 Analysts Covering the Most Companies')\n",
    "plt.xlabel('Analyst')\n",
    "plt.ylabel('Number of Companies')\n",
    "plt.show()\n",
    "\n",
    "# Find the analyst covering the most companies\n",
    "most_companies_analyst = analyst_coverage.idxmax()\n",
    "most_companies_coverage = analyst_coverage.max()\n",
    "\n",
    "print(f\"The analyst who covers the most companies is '{most_companies_analyst}' covering {most_companies_coverage} different companies.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6232219c",
   "metadata": {},
   "source": [
    "## 3. Similarity Matrix\n",
    "https://medium.com/analytics-vidhya/similarity-measures-for-categorical-data-d83a1812bbe9\n",
    "\n",
    "Based on how analysts organize themselves into covering companies,\n",
    "### a. Could you model the similarity or conversely, the distance matrix between the companies based on this analyst co-coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1c6c7295",
   "metadata": {},
   "source": [
    "categorical_features_ordinal = []\n",
    "categorical_features_one_hot = ['GICS_SECTOR_NAME', 'GICS_INDUSTRY_GROUP_NAME', 'BROKER']\n",
    "numerical_features = ['RATING']\n",
    "clean_pipeline = get_pipeline_clean_encode_only(categorical_features_one_hot, categorical_features_ordinal, numerical_features)\n",
    "\n",
    "# We only want to observe analyst 'Antpagna'\n",
    "# We also clean the dataset \n",
    "## -- Categorical features: One_hot/Ordinal encoding \n",
    "\n",
    "df_analyst_antpaga = df_clean[df_clean[\"ANALYST\"] == \"Antpagna\"].copy()\n",
    "\n",
    "# Remove duplicates\n",
    "df_analyst_antpaga = df_analyst_antpaga.drop_duplicates(subset=['BBTICKER']).reset_index(drop=True)\n",
    "\n",
    "df_company_antaga = df_analyst_antpaga[df_analyst_antpaga[\"BBTICKER\"].isin(df_analyst_antpaga['BBTICKER'].tolist())]\n",
    "df_preprocessed = clean_pipeline.fit_transform(df_company_antaga.copy())\n",
    "cols = df_analyst_antpaga[\"BBTICKER\"].tolist().copy()\n",
    "df_preprocessed.sample(7)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c56be9fd",
   "metadata": {},
   "source": [
    "df_preprocessed_sim = pd.DataFrame(data = cosine_similarity(df_preprocessed, df_preprocessed),  \n",
    "                                   index = cols, columns = cols)\n",
    "\n",
    "print(\"Shape of the similarity matrix:\", df_preprocessed_sim.shape)\n",
    "\n",
    "# Plot the similarity matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df_preprocessed_sim, cmap='viridis')\n",
    "plt.title('Similarity Matrix Based on Analyst Antpagna')\n",
    "plt.xlabel('Company')\n",
    "plt.ylabel('Company')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2ab7f724",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "abdb2fe5",
   "metadata": {},
   "source": [
    "# Create a pivot table where rows are analysts and columns are companies\n",
    "pivot_table = df.pivot_table(index='ANALYST', columns='BBTICKER', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Compute the similarity matrix (dot product of pivot table with its transpose)\n",
    "similarity_matrix = np.dot(pivot_table.T, pivot_table)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=pivot_table.columns, columns=pivot_table.columns)\n",
    "similarity_df\n",
    "# Print the shape of the similarity matrix\n",
    "print(\"Shape of the similarity matrix:\", similarity_df.shape)\n",
    "\n",
    "# Plot the similarity matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(similarity_df, cmap='viridis')\n",
    "plt.title('Similarity Matrix Based on Analyst Co-Coverage')\n",
    "plt.xlabel('Company')\n",
    "plt.ylabel('Company')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "675795dc",
   "metadata": {},
   "source": [
    "### b. How would the results change if you were to restrict the dataset to only analysts having companies covered within 1s.d. of the distribution found in Qn. 2?"
   ]
  },
  {
   "cell_type": "code",
   "id": "dd9bc704",
   "metadata": {},
   "source": [
    "# Calculate the mean and standard deviation of the number of companies covered by each analyst\n",
    "mean_coverage = analyst_coverage.mean()\n",
    "std_dev_coverage = analyst_coverage.std()\n",
    "\n",
    "# Filter analysts who cover companies within 1 standard deviation of the mean\n",
    "filtered_analysts = analyst_coverage[(analyst_coverage >= mean_coverage - std_dev_coverage) & \n",
    "                                     (analyst_coverage <= mean_coverage + std_dev_coverage)].index\n",
    "filtered_df = df_clean[df_clean['ANALYST'].isin(filtered_analysts)].copy()\n",
    "\n",
    "# Now, we find the analyst with the most coverage\n",
    "filtered_df_analyst_coverage = filtered_df['ANALYST'].value_counts()\n",
    "filtered_highest_analyst = filtered_df_analyst_coverage.head(1).index[0]\n",
    "print(\"The analyst with the most coverage after filtering: \" + filtered_highest_analyst)\n",
    "print()\n",
    "\n",
    "# Then, find the rows covered by analyst\n",
    "df_analyst = df_clean[df_clean[\"ANALYST\"] == filtered_highest_analyst].copy()\n",
    "# Remove duplicates\n",
    "df_analyst = df_analyst.drop_duplicates(subset=['BBTICKER']).reset_index(drop=True)\n",
    "\n",
    "df_preprocessed = clean_pipeline.fit_transform(df_analyst.copy())\n",
    "cols = df_analyst[\"BBTICKER\"].tolist().copy()\n",
    "\n",
    "df_preprocessed_sim = pd.DataFrame(data = cosine_similarity(df_preprocessed, df_preprocessed),  \n",
    "                                   index = cols, columns = cols)\n",
    "\n",
    "print(\"Shape of the similarity matrix:\", df_preprocessed_sim.shape)\n",
    "\n",
    "# Plot the similarity matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df_preprocessed_sim, cmap='viridis')\n",
    "plt.title('Similarity Matrix Based on Analyst ' + filtered_highest_analyst)\n",
    "plt.xlabel('Company')\n",
    "plt.ylabel('Company')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "71d7052b",
   "metadata": {},
   "source": [
    "# Calculate the mean and standard deviation of the number of companies covered by each analyst\n",
    "mean_coverage = analyst_coverage.mean()\n",
    "std_dev_coverage = analyst_coverage.std()\n",
    "\n",
    "# Filter analysts who cover companies within 1 standard deviation of the mean\n",
    "filtered_analysts = analyst_coverage[(analyst_coverage >= mean_coverage - std_dev_coverage) & \n",
    "                                     (analyst_coverage <= mean_coverage + std_dev_coverage)].index\n",
    "\n",
    "# Filter the dataframe to only include the filtered analysts\n",
    "filtered_df = df[df['ANALYST'].isin(filtered_analysts)]\n",
    "\n",
    "# Create a pivot table for the filtered analysts\n",
    "filtered_pivot_table = filtered_df.pivot_table(index='ANALYST', columns='BBTICKER', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Compute the similarity matrix for the filtered data\n",
    "filtered_similarity_matrix = np.dot(filtered_pivot_table.T, filtered_pivot_table)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "filtered_similarity_df = pd.DataFrame(filtered_similarity_matrix, index=filtered_pivot_table.columns, columns=filtered_pivot_table.columns)\n",
    "\n",
    "# Print the shape of the filtered similarity matrix\n",
    "print(\"Shape of the filtered similarity matrix:\", filtered_similarity_df.shape)\n",
    "\n",
    "# Plot the filtered similarity matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(filtered_similarity_df, cmap='viridis')\n",
    "plt.title('Filtered Similarity Matrix Based on Analyst Co-Coverage (within 1 SD)')\n",
    "plt.xlabel('Company')\n",
    "plt.ylabel('Company')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "352a7463",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa2eec96",
   "metadata": {},
   "source": [
    "### c. If further restricted to a smaller subset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42466ae2",
   "metadata": {},
   "source": [
    "For this example, let's further restrict the dataset by only choosing analysts within 0.25 s.d of the mean "
   ]
  },
  {
   "cell_type": "code",
   "id": "e452dcec",
   "metadata": {},
   "source": [
    "# Calculate the mean and standard deviation of the number of companies covered by each analyst\n",
    "mean_coverage = analyst_coverage.mean()\n",
    "std_dev_coverage = analyst_coverage.std()\n",
    "\n",
    "# Filter analysts who cover companies within 1 standard deviation of the mean\n",
    "filtered_analysts = analyst_coverage[(analyst_coverage >= mean_coverage - std_dev_coverage * 0.25) & \n",
    "                                     (analyst_coverage <= mean_coverage + std_dev_coverage * 0.25)].index\n",
    "filtered_df = df_clean[df_clean['ANALYST'].isin(filtered_analysts)].copy()\n",
    "\n",
    "# Now, we find the analyst with the most coverage\n",
    "filtered_df_analyst_coverage = filtered_df['ANALYST'].value_counts()\n",
    "filtered_highest_analyst = filtered_df_analyst_coverage.head(1).index[0]\n",
    "print(\"The analyst with the most coverage after filtering: \" + filtered_highest_analyst)\n",
    "print()\n",
    "\n",
    "# Then, find the rows covered by analyst\n",
    "df_analyst = df_clean[df_clean[\"ANALYST\"] == filtered_highest_analyst].copy()\n",
    "# Remove duplicates\n",
    "df_analyst = df_analyst.drop_duplicates(subset=['BBTICKER']).reset_index(drop=True)\n",
    "\n",
    "df_preprocessed = clean_pipeline.fit_transform(df_analyst.copy())\n",
    "cols = df_analyst[\"BBTICKER\"].tolist().copy()\n",
    "\n",
    "df_preprocessed_sim = pd.DataFrame(data = cosine_similarity(df_preprocessed, df_preprocessed),  \n",
    "                                   index = cols, columns = cols)\n",
    "\n",
    "print(\"Shape of the similarity matrix:\", df_preprocessed_sim.shape)\n",
    "\n",
    "# Plot the similarity matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df_preprocessed_sim, cmap='viridis')\n",
    "plt.title('Similarity Matrix Based on Analyst ' + filtered_highest_analyst)\n",
    "plt.xlabel('Company')\n",
    "plt.ylabel('Company')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "faf6023b",
   "metadata": {},
   "source": [
    "# Filter companies covered by 35 or more analysts\n",
    "company_coverage = df['BBTICKER'].value_counts()\n",
    "selected_companies = company_coverage[company_coverage >= 35].index\n",
    "\n",
    "# Filter the dataframe to only include the selected companies\n",
    "selected_df = df[df['BBTICKER'].isin(selected_companies)]\n",
    "\n",
    "# Create a pivot table for the selected companies\n",
    "selected_pivot_table = selected_df.pivot_table(index='ANALYST', columns='BBTICKER', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Compute the similarity matrix for the selected companies\n",
    "selected_similarity_matrix = np.dot(selected_pivot_table.T, selected_pivot_table)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "selected_similarity_df = pd.DataFrame(selected_similarity_matrix, index=selected_pivot_table.columns, columns=selected_pivot_table.columns)\n",
    "\n",
    "# Print the shape of the selected similarity matrix\n",
    "print(\"Shape of the selected similarity matrix:\", selected_similarity_df.shape)\n",
    "\n",
    "# Plot the selected similarity matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(selected_similarity_df, cmap='viridis')\n",
    "plt.title('Similarity Matrix for Companies Covered by 30 or More Analysts')\n",
    "plt.xlabel('Company')\n",
    "plt.ylabel('Company')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5f8d6885",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "63a7775c",
   "metadata": {},
   "source": [
    "# 4. Which sectors are the most heterogenous? (Look at the clusters formed by industry groups per sector – use t-SNE to visualize)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ff20e4ef",
   "metadata": {},
   "source": [
    "categorical_features_ordinal = []\n",
    "categorical_features_one_hot = ['GICS_SECTOR_NAME', 'RECOMMENDATION', 'ANALYST', 'BBTICKER']\n",
    "numerical_features = ['RATING', 'TARGET_PRICE']\n",
    "clean_pipeline = get_pipeline_clean_encode_impute(categorical_features_one_hot, categorical_features_ordinal, numerical_features)\n",
    "\n",
    "df_preprocessed = clean_pipeline.fit_transform(df.copy())\n",
    "cols = df[\"GICS_INDUSTRY_GROUP_NAME\"].tolist().copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0bf0f925",
   "metadata": {},
   "source": [
    "df_preprocessed"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0342eff9",
   "metadata": {},
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_STATE)\n",
    "X_tsne = tsne.fit_transform(df_preprocessed)\n",
    "tsne.kl_divergence_"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dce37e28",
   "metadata": {},
   "source": [
    "fig = px.scatter(x=X_tsne[:, 0], y=X_tsne[:, 1], color=cols)\n",
    "fig.update_layout(\n",
    "    title=\"t-SNE visualization of Custom Classification dataset\",\n",
    "    xaxis_title=\"First t-SNE\",\n",
    "    yaxis_title=\"Second t-SNE\",\n",
    ")\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a12c4913",
   "metadata": {},
   "source": [
    "X_tsne[:, 0].shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Clustering work in progress\n",
    "Can delete if not relevant\n",
    "\n",
    "Which sectors are the most heterogenous? (Look at the clusters formed\n",
    "by industry groups per sector – use t-SNE to visualize)"
   ],
   "id": "b0e713880806ee96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract the relevant columns for clustering\n",
    "relevant_columns = [\n",
    "    'BBTICKER', \n",
    "    'GICS_SECTOR_NAME', \n",
    "    'GICS_INDUSTRY_GROUP_NAME', \n",
    "    'ANALYST'\n",
    "]\n",
    "data_subset = df[relevant_columns].copy()\n",
    "\n",
    "# Drop duplicate rows based on BBTICKER column\n",
    "data_subset = data_subset.drop_duplicates(subset='BBTICKER').reset_index(drop=True)\n",
    "\n",
    "# import Encoding to convert Categorical Data into Labels\n",
    "# Handle categorical variables using Label Encoding\n",
    "label_encoders = {}\n",
    "for column in relevant_columns:\n",
    "    le = LabelEncoder()\n",
    "    data_subset[column] = le.fit_transform(data_subset[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Apply t-SNE to reduce the dimensionality to 2D using the encoded columns\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "data_tsne = tsne.fit_transform(data_subset)\n",
    "\n",
    "# Convert the result to a DataFrame for visualization and analysis\n",
    "tsne_df = pd.DataFrame(data_tsne, columns=['TSNE1', 'TSNE2'])\n",
    "tsne_df['GICS_SECTOR_NAME'] = df['GICS_SECTOR_NAME']\n",
    "tsne_df['BBTICKER'] = df['BBTICKER']\n",
    "\n",
    " # Plot the t-SNE clusters using seaborn\n",
    "plt.figure(figsize=(16, 9))\n",
    "scatterplot = sns.scatterplot(x='TSNE1', y='TSNE2', hue='GICS_SECTOR_NAME', style='GICS_SECTOR_NAME', data=tsne_df, palette='tab10', alpha=0.8)\n",
    "\n"
   ],
   "id": "7541d8a5ffdced85",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
