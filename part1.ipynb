{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T11:26:28.919408Z",
     "start_time": "2024-05-23T11:26:28.913384Z"
    }
   },
   "source": [
    "# Importing necessary libraries for data cleaning and exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "2b1a1bcd26d0e1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T11:26:30.331069Z",
     "start_time": "2024-05-23T11:26:30.233229Z"
    }
   },
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Data/QF632_Project_1.csv')\n",
    "\n",
    "# Examine the structure and summary\n",
    "print(df.info())\n",
    "print(df.describe())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1038 entries, 0 to 1037\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       1038 non-null   object \n",
      " 1   Signal     1038 non-null   float64\n",
      " 2   Open       1038 non-null   float64\n",
      " 3   High       1038 non-null   float64\n",
      " 4   Low        1038 non-null   float64\n",
      " 5   Close      1038 non-null   float64\n",
      " 6   Adj Close  1038 non-null   float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 56.9+ KB\n",
      "None\n",
      "            Signal         Open         High          Low        Close  \\\n",
      "count  1038.000000  1038.000000  1038.000000  1038.000000  1038.000000   \n",
      "mean     16.766190   141.847360   142.691801   140.907746   141.840973   \n",
      "std       3.095783    18.475574    18.470255    18.404504    18.497010   \n",
      "min       0.000000    94.080002    95.400002    93.639999    94.790001   \n",
      "25%      14.691150   132.132496   132.912495   130.542503   131.824993   \n",
      "50%      17.298240   146.769997   147.959999   145.634995   146.885002   \n",
      "75%      19.030890   155.367496   156.287495   154.422500   155.289993   \n",
      "max      35.434147   172.789993   173.389999   171.949997   196.279999   \n",
      "\n",
      "         Adj Close  \n",
      "count  1038.000000  \n",
      "mean    136.341060  \n",
      "std      21.427837  \n",
      "min    -152.277847  \n",
      "25%     125.290491  \n",
      "50%     142.667732  \n",
      "75%     151.798325  \n",
      "max     168.842270  \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "2ea37f1e8d47c766",
   "metadata": {},
   "source": [
    "# Table of Contents <a name=\"tableofcontents\"></a>\n",
    "1. [Review the quality of the data, list any potential errors, and propose corrected values. Please list each quality check error and correction applied.](#part1)\n",
    "2. [Please analyze the signal’s effectiveness or lack thereof in forecasting ETF price, using whatever metrics you think are most relevant.](#part2)\n",
    "3. [Run any exploratory data analysis you think is important and highlight any interesting insights you come across. ](#part3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652e03fd831f88c",
   "metadata": {},
   "source": [
    "# part1 \n",
    "Review the quality of the data, list any potential errors, and propose corrected values. Please list each quality check error and correction applied.\n",
    "\n",
    "a.\tCheck object types\n",
    "\n",
    "b.\tCheck for nan values\n",
    "\n",
    "    i.\tInterpolate or forward fill. If interpolate, be careful not to include future rows \n",
    "\n",
    "c.\tDifference all first\n",
    "\n",
    "d.\tScatter plot/boxplot for outliers\n",
    "\n",
    "    i.\tSee if need outlier handling (If no, maybe justify why)\n"
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def length_test(df):\n",
    "    # Check the length of the dataset\n",
    "    if len(df) > 0:\n",
    "        result = True\n",
    "    elif len(df) == 0:\n",
    "        result = False\n",
    "    return result"
   ],
   "id": "11ca17316d435f4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def missing_test(df):\n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    if len(missing_values) > 0:\n",
    "        result = True\n",
    "    elif len(missing_values) == 0:\n",
    "        result = False\n",
    "    return result"
   ],
   "id": "c44087c10e0af2fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def duplicate_test(df):\n",
    "    # Check for duplicated rows\n",
    "    duplicated_rows = df[df.duplicated()]\n",
    "    if duplicated_rows.empty:\n",
    "        result = True\n",
    "    elif len(duplicated_rows) > 0:\n",
    "        result = False\n",
    "        df = df.drop_duplicates()\n",
    "    return result, df"
   ],
   "id": "79ff9195610410b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T11:27:52.510817Z",
     "start_time": "2024-05-23T11:27:52.353427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def date_test(df):\n",
    "    # Ensure dates are in the right format and sequence\n",
    "    date_check = df['Date'].apply(pd.to_datetime, errors='coerce').isnull().sum()\n",
    "    if date_check == 0:\n",
    "        result = True\n",
    "    elif date_check != 0:\n",
    "        result = False\n",
    "    return result"
   ],
   "id": "ea0476632038ae45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1038 entries, 0 to 1037\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       1038 non-null   object \n",
      " 1   Signal     1038 non-null   float64\n",
      " 2   Open       1038 non-null   float64\n",
      " 3   High       1038 non-null   float64\n",
      " 4   Low        1038 non-null   float64\n",
      " 5   Close      1038 non-null   float64\n",
      " 6   Adj Close  1038 non-null   float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 56.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def datatype_test(df):\n",
    "    pass"
   ],
   "id": "215474b33db77d7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70d45b4a9fefd5d4",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Review the quality of the data\n",
    "def review_data_quality(df):\n",
    "    errors = []\n",
    "    \n",
    "    # Check the length of the dataset\n",
    "    length_check = length_test(df)\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_check = missing_test(df)\n",
    "    \n",
    "    # Check for duplicated rows\n",
    "    duplicate_check, df = duplicate_test(df)\n",
    "        \n",
    "    # Check dates are in the right format and sequence\n",
    "    date_check = date_test(df)\n",
    "    \n",
    "    # Check Object DataTypes\n",
    "    # datatype_check = datatype_test(df)\n",
    "        # Check and correct data types\n",
    "    expected_types = {\n",
    "        'Date': 'datetime64[ns]',\n",
    "        'Signal': 'float64',\n",
    "        'Open': 'float64',\n",
    "        'High': 'float64',\n",
    "        'Low': 'float64',\n",
    "        'Close': 'float64',\n",
    "        'Adj Close': 'float64',\n",
    "    }\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df['Signal'] = pd.to_numeric(df['Signal'], errors='coerce')\n",
    "    df['Open'] = pd.to_numeric(df['Open'], errors='coerce')\n",
    "    df['High'] = pd.to_numeric(df['High'], errors='coerce')\n",
    "    df['Low'] = pd.to_numeric(df['Low'], errors='coerce')\n",
    "    df['Close'] = pd.to_numeric(df['Close'], errors='coerce')\n",
    "    df['Adj Close'] = pd.to_numeric(df['Adj Close'], errors='coerce')\n",
    "    \n",
    "    \n",
    "    # Collect errors for data type mismatches\n",
    "    for column, expected_type in expected_types.items():\n",
    "        if df[column].dtype != expected_type:\n",
    "            errors.append(f\"Column '{column}' is of type {df[column].dtype} but expected {expected_type}.\")\n",
    "\n",
    "    # Check for NaN values and handle them\n",
    "    nan_summary = df.isna().sum()\n",
    "    nan_columns = nan_summary[nan_summary > 0].index.tolist()\n",
    "\n",
    "    for column in nan_columns:\n",
    "        errors.append(f\"Column '{column}' has {nan_summary[column]} NaN values.\")\n",
    "        # Interpolate or forward fill, careful not to include future rows\n",
    "        df[column] = df[column].interpolate(method='linear', limit_direction='forward')\n",
    "        # Fill remaining NaNs if interpolation cannot fill them\n",
    "        df[column] = df[column].fillna(method='ffill')\n",
    "\n",
    "    return errors, df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "55d85ae9fad44df2",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Difference all columns except Date\n",
    "def difference_columns(df):\n",
    "    df_diff = df.copy()\n",
    "    df_diff.iloc[:, 1:] = df_diff.iloc[:, 1:].diff()\n",
    "    return df_diff.dropna()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1b682956fc2d174",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Identify outliers using IQR method\n",
    "def identify_outliers(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return (series < lower_bound) | (series > upper_bound)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd128db8883e4506",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Plotting functions for outlier detection\n",
    "def plot_outliers(df):\n",
    "    numeric_columns = df.select_dtypes(include=['float64']).columns\n",
    "\n",
    "    # Scatter plots with outliers highlighted\n",
    "    for column in numeric_columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(df['Date'], df[column], alpha=0.5, label='Data')\n",
    "        \n",
    "        # Identify and plot outliers\n",
    "        outliers = identify_outliers(df[column])\n",
    "        plt.scatter(df['Date'][outliers], df[column][outliers], color='red', label='Outliers')\n",
    "        \n",
    "        plt.title(f'Scatter Plot of {column} over Time')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel(column)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    # Box plots\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    df[numeric_columns].boxplot()\n",
    "    plt.title('Box Plot of Numeric Columns')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec4d482e67a04b98",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Main cleaning function\n",
    "def clean_data(file_path):\n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Review data quality and apply corrections\n",
    "    errors, df_cleaned = review_data_quality(df)\n",
    "    \n",
    "    # Difference all columns except Date\n",
    "    df_diff = difference_columns(df_cleaned)\n",
    "    \n",
    "    return errors, df_cleaned, df_diff"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9738884c487e2621",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Usage example\n",
    "errors, df_cleaned, df_diff = clean_data('Data/QF632_Project_1.csv')\n",
    "\n",
    "print('df_cleaned length', len(df_cleaned))\n",
    "print('df_diff length', len(df_diff))\n",
    "\n",
    "\n",
    "# Output the results\n",
    "print(\"Data Quality Errors and Corrections:\")\n",
    "for error in errors:\n",
    "    print(error)\n",
    "\n",
    "print(\"\\nCleaned Data:\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "print(\"\\nDifferenced Data:\")\n",
    "print(df_diff.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d626790124146121",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Plotting outliers\n",
    "\n",
    "plot_outliers(df_cleaned)\n",
    "# TimeSeries price\n",
    "# Continuous Nature:\n",
    "# Time series price data is typically continuous during regular trading hours, meaning there should not have large, abrupt changes from one point to the next during this period.\n",
    "# \n",
    "# After-Hours Trading:\n",
    "# Prices can exhibit significant gaps between the closing price of one day and the opening price of the next trading day due to after-hours trading activities, news, earnings reports, and other factors.\n",
    "# These gaps can appear as outliers when the data is visualized or analyzed."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d53a4fc5e2012045",
   "metadata": {},
   "source": [
    "# part2\n",
    "Please analyze the signal’s effectiveness or lack thereof in forecasting ETF price, using whatever metrics you think are most relevant.\n",
    "\n",
    "\n",
    "a.\tCross correlation\n",
    "\n",
    "b.\tKurtosis & skew\n",
    "\n",
    "c.\tR2 score from Lasso, Ridge & RandomForest\n",
    "\n",
    "d.\tACF, PACF of signal, ETF\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "89882920e2c41a15",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4ed92e7180d6379",
   "metadata": {},
   "source": [
    "# part3 \n",
    "Run any exploratory data analysis you think is important and highlight any interesting insights you come across.\n",
    "\n",
    "a.\tUhhh same as parts 1 &2 unless yall can think of smth else\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b24da21dbc481ed5",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e2c8ab8374be42a",
   "metadata": {},
   "source": "[Return to the Top](#part1-)"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "42724698e2591203",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
